{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CNOwkeKEi0CO"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the Yellow Pages page to scrape\n",
        "url = 'https://www.yellowpages.com/search?search_terms=manufacturing&geo_location_terms=Dallas%2C+TX'"
      ],
      "metadata": {
        "id": "ytlB_LJxi3LX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a request to the page and parse it\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Lists to store the extracted data\n",
        "company_names = []\n",
        "websites = []\n",
        "contact_numbers = []\n",
        "locations = []\n",
        "categories = []\n",
        "emails = []\n",
        "Country=[]"
      ],
      "metadata": {
        "id": "yPkKdtnOi6MK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for business in soup.find_all('div', class_='info'):\n",
        "    business_name_tag = business.find('a', class_='business-name')\n",
        "\n",
        "    # Check if the business name exists and get the text\n",
        "    if business_name_tag:\n",
        "        business_name = business_name_tag.find('span').text.strip() if business_name_tag.find('span') else 'N/A'\n",
        "    else:\n",
        "        business_name = 'N/A'\n",
        "\n",
        "    # Append to the company_names list\n",
        "    company_names.append(business_name)"
      ],
      "metadata": {
        "id": "OqkfuGQri-Ja"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for business in soup.find_all('div', class_='info'):\n",
        "    business_name_tag = business.find('a', class_='categories')\n",
        "\n",
        "    # Check if the business name exists and get the text\n",
        "    if business_name_tag:\n",
        "        business_name = business_name_tag.find('span').text.strip() if business_name_tag.find('span') else 'N/A'\n",
        "    else:\n",
        "        business_name = 'N/A'\n",
        "\n",
        "    # Append to the company_names list\n",
        "    company_names.append(business_name)\n",
        "\n",
        "# Print the result\n",
        "print(company_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6P8ioeojCJ5",
        "outputId": "f88aa83e-5d1f-43dd-9b78-d9e70a6cd87b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Marr Brothers Inc', 'Elgin B Robertson Inc', 'Titan Laboratories', 'FOUR STATES MOBILE HOMES AND LAND', 'Royal Oaks Mobil Home Park', 'The Leather Hospital', 'Auto Link Dallas', 'Crouch Sales Company', 'USA Mattress', 'Mary Kay Cosmetics-Manufacturing', 'South Coast Product Inc', 'Tortilleria Y Taqueria Galindo', 'ABC Auto Parts', 'Lucky Wholesale', 'Eagle Circuit', 'A 1 Auto Partes', 'Dallas Manufacturing Corporation', 'City Electric Supply', 'Ferguson Bath, Kitchen & Lighting Gallery', 'Apex Supply Company', 'Groovystuff Furniture & Accessories', 'Chair Care Patio', 'SILLA AUTOMOTIVE LLC. DALLAS', 'CED Dallas', 'American Freight Furniture, Mattress, Appliance', 'North Dallas Office Furniture', 'Hi-Line, Inc.', 'US Truck Parts', 'San Roseland Corporation', \"Lucky's Mattress Outlet\", 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for business in soup.find_all('div',class_='links'):\n",
        "    business_links=business.find('a',class_='track-visit-website')\n",
        "    if  business_links:\n",
        "          business_links = business_links.get('href', 'N/A').strip()\n",
        "    else:\n",
        "      business_links='N/A'\n",
        "    websites.append(business_links)\n",
        "\n",
        "print(websites)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVSlFiYjjLko",
        "outputId": "f6d5e404-e2ae-40fc-b8ed-92287dbc831a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.marrbros.com', 'http://www.ebr.net', 'https://www.titanlabs.net', 'N/A', 'N/A', 'N/A', 'N/A', 'http://crouchsales.com', 'N/A', 'https://www.marykay.com', 'N/A', 'N/A', 'http://www.abcauto.com', 'N/A', 'http://www.eaglecircuits.com', 'http://www.a1dallas.com', 'N/A', 'http://www.cityelectricsupply.com', 'http://www.ferguson.com', 'http://www.apexsupplyco.com', 'http://groovystuff.com', 'http://www.chaircarepatio.com', 'N/A', 'http://www.ceddallas.com', 'https://www.americanfreight.com/store/tx/dallas/127?utm_medium=organic&utm_source=local&utm_campaign=yextpowerlistings&utm_content=fma&utm_term=127', 'N/A', 'http://www.hi-line.com', 'http://www.ustruckpartsinc.com', 'http://sanroseland.com/contact_us', 'N/A']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for business  in soup.find_all('div',class_='phones phone primary'):\n",
        "  if business:\n",
        "      business_number = business.text.strip() if business else 'N/A'\n",
        "  else:\n",
        "    business_number='N/A'\n",
        "  contact_numbers.append(business_number)\n",
        "print(contact_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exgq4_aVjO3W",
        "outputId": "ce90a482-aeaa-4260-d212-115dde5e3005"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(844) 385-6356', '(214) 333-2341', '(214) 951-0993', '(903) 372-8811', '(972) 286-8586', '(972) 241-1014', '(214) 351-0789', '(214) 637-6051', '(214) 887-6615', '(972) 687-5533', '(214) 747-8118', '(214) 331-5744', '(214) 398-8303', '(972) 241-7862', '(214) 349-0288', '(214) 428-0115', '(972) 716-4200', '(866) 634-9853', '(214) 761-9333', '(214) 741-5463', '(214) 956-0536', '(214) 638-6416', '(972) 444-9200', '(214) 932-3000', '(972) 283-8888', '(972) 960-7800', '(972) 247-6200', '(972) 557-7979', '(214) 503-6333', '(214) 766-8010']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for business  in soup.find_all('div',class_='phones phone primary'):\n",
        "  if business:\n",
        "      business_number = business.text.strip() if business else 'N/A'\n",
        "  else:\n",
        "    business_number='N/A'\n",
        "  contact_numbers.append(business_number)\n",
        "print(contact_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mew_YbzEjRfu",
        "outputId": "0cf819c3-c36f-4b48-e0f0-2d061d377627"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(844) 385-6356', '(214) 333-2341', '(214) 951-0993', '(903) 372-8811', '(972) 286-8586', '(972) 241-1014', '(214) 351-0789', '(214) 637-6051', '(214) 887-6615', '(972) 687-5533', '(214) 747-8118', '(214) 331-5744', '(214) 398-8303', '(972) 241-7862', '(214) 349-0288', '(214) 428-0115', '(972) 716-4200', '(866) 634-9853', '(214) 761-9333', '(214) 741-5463', '(214) 956-0536', '(214) 638-6416', '(972) 444-9200', '(214) 932-3000', '(972) 283-8888', '(972) 960-7800', '(972) 247-6200', '(972) 557-7979', '(214) 503-6333', '(214) 766-8010', '(844) 385-6356', '(214) 333-2341', '(214) 951-0993', '(903) 372-8811', '(972) 286-8586', '(972) 241-1014', '(214) 351-0789', '(214) 637-6051', '(214) 887-6615', '(972) 687-5533', '(214) 747-8118', '(214) 331-5744', '(214) 398-8303', '(972) 241-7862', '(214) 349-0288', '(214) 428-0115', '(972) 716-4200', '(866) 634-9853', '(214) 761-9333', '(214) 741-5463', '(214) 956-0536', '(214) 638-6416', '(972) 444-9200', '(214) 932-3000', '(972) 283-8888', '(972) 960-7800', '(972) 247-6200', '(972) 557-7979', '(214) 503-6333', '(214) 766-8010']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for business in soup.find_all('div', class_='adr'):\n",
        "    # Extract street address\n",
        "    street_address = business.find('div', class_='street-address')\n",
        "    # Extract locality (city, state, zip code)\n",
        "    locality = business.find('div', class_='locality')\n",
        "\n",
        "    # Get street address and locality values, if they exist\n",
        "    bussiness_street = street_address.text.strip() if street_address else 'N/A'\n",
        "    bussiness_street_address = locality.text.strip() if locality else 'N/A'\n",
        "\n",
        "    # Append to the respective lists\n",
        "    locations.append(bussiness_street)\n",
        "    Country.append(bussiness_street_address)\n",
        "\n",
        "# Print the lists\n",
        "print(\"Street Addresses:\", locations)\n",
        "print(\"Locality:\", Country)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpVmdYk4jUvN",
        "outputId": "4b6e955b-d81c-450d-bc92-449623692807"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Street Addresses: ['423 East Jefferson Boulevard', '4426 Mint Way', '2935 Irving Blvd', 'P O Box 710666', '11526 C F Hawn Fwy', '11181 Harry Hines Blvd Ste 142', '2603 Southwell Rd', '2636 Irving Blvd', '1707 Alpine St', '1330 Regal Row', '2500 S Harwood St', '2475 S Cockrell Hill Rd', '8836 Lake June Rd', '11422 Harry Hines Blvd Ste 107', '10820 Sanden Dr', '5427 S Lamar St', '4215 McEwen Rd', '400 S Record St', '1403 Slocum St', '180 Oak Lawn Ave', '3229 Halifax St', '8700 Sovereign Row', '10610 Newkirk St Ste 208', '11560 Hillguard Rd', '2964 W Wheatland Rd', '4550 McEwen Rd', '2121 Valley View Ln', '13121 C F Hawn Fwy', '10470 Plano Rd', '2445 W Northwest Hwy Ste 105']\n",
            "Locality: ['Dallas, TX 75203', 'Dallas, TX 75236', 'Dallas, TX 75247', 'Dallas, TX 75371', 'Dallas, TX 75253', 'Dallas, TX 75229', 'Dallas, TX 75229', 'Dallas, TX 75207', 'Dallas, TX 75223', 'Dallas, TX 75247', 'Dallas, TX 75215', 'Dallas, TX 75211', 'Dallas, TX 75217', 'Dallas, TX 75229', 'Dallas, TX 75238', 'Dallas, TX 75215', 'Dallas, TX 75244', 'Dallas, TX 75202', 'Dallas, TX 75207', 'Dallas, TX 75207', 'Dallas, TX 75247', 'Dallas, TX 75247', 'Dallas, TX 75220', 'Dallas, TX 75243', 'Dallas, TX 75237', 'Dallas, TX 75244', 'Dallas, TX 75234', 'Dallas, TX 75253', 'Dallas, TX 75238', 'Dallas, TX 75220']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Combine all the extracted lists into a dictionary\n",
        "# data = {\n",
        "#     'Company Name': company_names,\n",
        "#     'Category': categories,  # You had category extraction code, make sure to fill that list if needed\n",
        "#     'Website': websites,\n",
        "#     'Contact Number': contact_numbers,\n",
        "#     'Street Address': locations,\n",
        "#     'Locality': Country,\n",
        "# }\n",
        "\n",
        "# # Create a DataFrame\n",
        "# df = pd.DataFrame(data)\n",
        "\n",
        "# # Write the DataFrame to an Excel file\n",
        "# df.to_excel('scraped_data.xlsx', index=False)\n",
        "\n",
        "# print(\"Data saved to 'scraped_data.xlsx' successfully.\")"
      ],
      "metadata": {
        "id": "KXQNAx_TjYGu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = {\n",
        "    'company_names': len(company_names),\n",
        "    'websites': len(websites),\n",
        "    'contact_numbers': len(contact_numbers),\n",
        "    'locations': len(locations),\n",
        "    'Country': len(Country),\n",
        "    'categories': len(categories),  # Ensure this list is also filled if you are using it\n",
        "}\n",
        "\n",
        "print(\"Lengths of the lists:\", lengths)\n",
        "\n",
        "# If the lists don't have the same length, we'll pad the shorter lists with 'N/A'\n",
        "max_length = max(lengths.values())  # Find the length of the longest list\n",
        "\n",
        "# Pad shorter lists with 'N/A'\n",
        "company_names += ['N/A'] * (max_length - len(company_names))\n",
        "websites += ['N/A'] * (max_length - len(websites))\n",
        "contact_numbers += ['N/A'] * (max_length - len(contact_numbers))\n",
        "locations += ['N/A'] * (max_length - len(locations))\n",
        "Country += ['N/A'] * (max_length - len(Country))\n",
        "categories += ['N/A'] * (max_length - len(categories))\n",
        "\n",
        "# Combine all the extracted lists into a dictionary\n",
        "data = {\n",
        "    'Company Name': company_names,\n",
        "    'Category': categories,\n",
        "    'Website': websites,\n",
        "    'Contact Number': contact_numbers,\n",
        "    'Street Address': locations,\n",
        "    'Locality': Country,\n",
        "}\n",
        "\n",
        "# # Create a DataFrame\n",
        "# df = pd.DataFrame(data)\n",
        "# df.to_excel('scraped_data.xlsx', index=False)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df[df['Company Name'] != 'N/A']  # Filter rows with 'N/A' in 'Company Name'\n",
        "df.to_excel('scraped_data_filtered.xlsx', index=False)\n",
        "\n",
        "print(\"Data saved to 'scraped_data.xlsx' successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QlmAY9ojeZj",
        "outputId": "e2593be5-7cf0-475d-cc6e-90a9cfcafe55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lengths of the lists: {'company_names': 60, 'websites': 60, 'contact_numbers': 60, 'locations': 60, 'Country': 60, 'categories': 60}\n",
            "Data saved to 'scraped_data.xlsx' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ecJTxlCEjjlr"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}